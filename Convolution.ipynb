{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLaRUYVRc4mXNzmZO9UWYc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SlyviaCC/AI/blob/main/Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aww4BE9gxGsK",
        "outputId": "e8587462-7a91-45b0-e354-798d82ec0cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 27s 8ms/step - loss: 2.2756 - accuracy: 0.2328 - val_loss: 2.2517 - val_accuracy: 0.2889\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.2195 - accuracy: 0.3218 - val_loss: 2.1821 - val_accuracy: 0.3639\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.1249 - accuracy: 0.4025 - val_loss: 2.0564 - val_accuracy: 0.4424\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 1.9661 - accuracy: 0.4574 - val_loss: 1.8617 - val_accuracy: 0.4894\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 1.7446 - accuracy: 0.5155 - val_loss: 1.6130 - val_accuracy: 0.5589\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.6130 - accuracy: 0.5589\n",
            "test loss: 1.6129978895187378\n",
            "test accuracy: 0.558899998664856\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from PIL  import Image           #PIL是python的图像库\n",
        "import matplotlib.pyplot as plt  #matplotlib.pyplot是一个可以操作图像的函数库\n",
        "from keras.models import Sequential  #Keras的核心数据结构是model,一种组织网络层的方式，最简单的数据模型是Sequential模型，它是由多个网络层线性\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten  #dense ：全连接层  相当于添加一个层\n",
        "#Conv2D：二维卷积 14*14\n",
        "# MaxPooling2D 最大池化\n",
        "# Flatten '压平'为了实现从卷积完成后压平给到全连接（dense）的过度\n",
        "'''默认是进行行压平，也可以列压平\n",
        "from numpy import *\n",
        ">>> a=array([[1,2],[3,4],[5,6]])\n",
        ">>> a\n",
        "array([[1, 2],\n",
        "    [3, 4],\n",
        "    [5, 6]])\n",
        ">>> a.flatten() #默认按行的方向降维\n",
        "array([1, 2, 3, 4, 5, 6])\n",
        ">>> a.flatten('F') #按列降维\n",
        "array([1, 3, 5, 2, 4, 6]) \n",
        ">>> a.flatten('A') #按行降维\n",
        "array([1, 2, 3, 4, 5, 6])\n",
        "'''\n",
        "\n",
        "batch_size=32  #BATCH_SIZE:即一次训练所抓取的数据样本数量; BATCH_SIZE的大小影响训练速度和模型优化。同时按照以上代码可知,其大小同样影响每一epoch训练模型次数。\n",
        "num_classes=10 #看需求，需要多少个类就用多少个类\n",
        "\n",
        "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape,train_labels.shape)\n",
        "print(test_images.shape,test_labels.shape)\n",
        "\n",
        "\"\"\"\n",
        "将数据集中图片展示出来\n",
        "\"\"\"\n",
        "\n",
        "def show_mnist(train_image,train_labels):\n",
        "    n = 3\n",
        "    m = 3\n",
        "    fig = plt.figure()\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            plt.subplot(n,m,i*n+j+1) #subplot是将多个图画到一个平面上的工具。其中,m表示是图排成m行,n表示图排成n列，p是绘图编号\n",
        "            #plt.subplots_adjust(wspace=0.2, hspace=0.8)\n",
        "            index = i * n + j #当前图片的标号\n",
        "            img_array = train_image[index]\n",
        "            img = Image.fromarray(img_array)  #这个函数的功能是重构图像的数组\n",
        "            plt.title(train_labels[index])\n",
        "            plt.imshow(img,cmap='Greys')    #imshow是将矩阵中的每个元素值当作像素值进行显示；（还有说是待处理的图像）\n",
        "    plt.show()      #原理：plt.imshow()函数负责对图像进行处理，并显示其格式，而plt.show()则是将plt.imshow()处理后的函数显示出来。\n",
        "\n",
        "img_row,img_col,channel = 28,28,1\n",
        "\n",
        "mnist_input_shape = (img_row,img_col,1)\n",
        "\n",
        "#将数据维度进行处理\n",
        "train_images = train_images.reshape(train_images.shape[0],img_row,img_col,channel)\n",
        "test_images = test_images.reshape(test_images.shape[0],img_row,img_col,channel)\n",
        "\n",
        "train_images = train_images.astype(\"float32\")\n",
        "test_images = test_images.astype(\"float32\")\n",
        "\n",
        "## 进行归一化处理\n",
        "# 其功能就是将预处理的数据的数值范围按一定关系“压缩”到一定的范围内。\n",
        "train_images  /= 255\n",
        "test_images /= 255\n",
        "\n",
        "# 将类向量，转化为类矩阵\n",
        "# 从 5 转换为 0 0 0 0 1 0 0 0 0 0 矩阵\n",
        "train_labels =tf.keras.utils.to_categorical(train_labels,num_classes)\n",
        "test_labels =tf.keras.utils.to_categorical(test_labels,num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "构造网络结构\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),\n",
        "                    activation=\"relu\",\n",
        "                    input_shape=mnist_input_shape))\n",
        "                    # kernalsize = 3*3 并没有改变数据维度\n",
        "model.add(Conv2D(16,kernel_size=(3,3),\n",
        "                    activation=\"relu\"\n",
        "                    ))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "                    # 进行数据降维操作\n",
        "model.add(Flatten())#Flatten层用来将输入“压平”，即把多维的输入一维化，\n",
        "                    #常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。\n",
        "model.add(Dense(32,activation=\"relu\"))\n",
        "                    #全连接层\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "\"\"\"\n",
        "编译网络模型,添加一些超参数\n",
        "Adadelta 优化是一种随机梯度下降方法，它基于每维度的自适应学习率来解决两个缺点：\n",
        "1.整个训练过程中学习率的持续衰减。\n",
        "2.需要手动选择全局学习率。\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adadelta(),      \n",
        "                metrics=['accuracy'])\n",
        "'''实例化是指在面向对象的编程中，把用类创建对象的过程称为实例化。是将一个抽象的概念类，具体到该类实物的过程。\n",
        "实例化过程中一般由类名 对象名 = new 类名（参数1，参数2...参数n）构成。\n",
        "函数模板实例化后会生成模板函数，类模板实例化后则会生成模板类。'''\n",
        "model.fit(train_images,\n",
        "            train_labels,\n",
        "            batch_size=batch_size,    \n",
        "            epochs=5,\n",
        "            verbose=1,\n",
        "            validation_data=(test_images,test_labels),\n",
        "            shuffle=True\n",
        "            )\n",
        "'''\n",
        "batch_size：整数：每次梯度更新的样本数。未指定，默认为32   \n",
        "epochs:整数:训练模型迭代次数\n",
        "\n",
        "verbose:日志展示，整数\n",
        "0:为不在标准输出流输出日志信息\n",
        "1:显示进度条\n",
        "2:每个epoch输出一行记录\n",
        "\n",
        "callbacks\n",
        "其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数\n",
        "\n",
        "validation_split\n",
        "浮点数0-1之间\n",
        "用作验证集的训练数据的比例。\n",
        "模型将分出一部分不会被训练的验证数据，并将在每一轮结束时评估这些验证数据的误差和任何其他模型指标。\n",
        "验 证 数 据 是 混 洗 之 前 x 和 y 数 据 的 最 后 一 部 分 样 本 中 \n",
        "\n",
        "shuffle\n",
        "布尔值\n",
        "是否在每轮迭代之前混洗数据\n",
        "\n",
        "shuffle\n",
        "布尔值\n",
        "是否在每轮迭代之前混洗数据\n",
        "\n",
        "'''\n",
        "score = model.evaluate(test_images,test_labels,verbose=1)\n",
        "\n",
        "print('test loss:',score[0])\n",
        "print('test accuracy:',score[1])"
      ]
    }
  ]
}